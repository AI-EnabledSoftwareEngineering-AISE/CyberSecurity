{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3755,
     "status": "ok",
     "timestamp": 1666664590832,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "voNnpdstvF67",
    "outputId": "95752794-47bf-43fb-b8fd-a273495f1525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from torch) (4.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12166,
     "status": "ok",
     "timestamp": 1666664605470,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "ISdXfea9vYAZ",
    "outputId": "aab95602-0486-404a-bcdb-4cc7a8232111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.0/757.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from transformers) (4.11.3)\n",
      "Requirement already satisfied: requests in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.17\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, tqdm, regex, pyyaml, numpy, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.10.1 numpy-1.21.6 pyyaml-6.0 regex-2022.9.13 tokenizers-0.13.1 tqdm-4.64.1 transformers-4.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5qC09FIVvWGw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666664634982,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "4Vd__Ti9voEZ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2270,
     "status": "ok",
     "timestamp": 1666664638769,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "hOPkA0eQv0Oz"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iwu07Cqtv9cF"
   },
   "outputs": [],
   "source": [
    "nl_tokens=tokenizer.tokenize(\"return maximum value\")\n",
    "code_tokens=tokenizer.tokenize(\"def max(a,b): if a>b: return a else return b\")\n",
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "context_embeddings=model(torch.tensor(tokens_ids)[None,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oAM5spNkgTw"
   },
   "outputs": [],
   "source": [
    "# merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21083,
     "status": "ok",
     "timestamp": 1666664661375,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "QFlu8bpPl6_g",
    "outputId": "61510dfb-c959-4523-b70b-e094cd840997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1666664663850,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "fIduwRi9mA0e",
    "outputId": "fc030537-601f-487f-fb50-b045621f6a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/codeBert\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/codeBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G84rGTfxzJh4"
   },
   "outputs": [],
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.10-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1666664667576,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "gi2TnGF0zLtY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"JavaDataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "IW4qFLW8zVJW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CWE-ID</th>\n",
       "      <th>CVE-ID</th>\n",
       "      <th>Git Link</th>\n",
       "      <th>File Name</th>\n",
       "      <th>commit</th>\n",
       "      <th>Language</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "      <th>Commit Message</th>\n",
       "      <th>CWE Name</th>\n",
       "      <th>CWE Description</th>\n",
       "      <th>CWE Extended Description</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CWE-119</td>\n",
       "      <td>CVE-2014-3488</td>\n",
       "      <td>https://github.com/netty/netty/commit/2fa9400a...</td>\n",
       "      <td>SslHandler.java</td>\n",
       "      <td>2fa9400a59d0563a66908aba55c41e7285a04994</td>\n",
       "      <td>java</td>\n",
       "      <td>result = engine.un...</td>\n",
       "      <td>final int outAppBufSiz...</td>\n",
       "      <td>Fix a bug where SslHandler does not handle SSL...</td>\n",
       "      <td>Improper Restriction of Operations within the ...</td>\n",
       "      <td>The software performs operations on a memory b...</td>\n",
       "      <td>Certain languages allow direct addressing of m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "      <td>869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CWE-755</td>\n",
       "      <td>CVE-2018-8039</td>\n",
       "      <td>https://github.com/apache/cxf/commit/fae6fabf9...</td>\n",
       "      <td>HttpsURLConnectionFactory.java</td>\n",
       "      <td>fae6fabf9bd7647f5e9cb68897a7d72b545b741b</td>\n",
       "      <td>java</td>\n",
       "      <td>return true;\\n</td>\n",
       "      <td>return false;\\n</td>\n",
       "      <td>Fix hostname verification using the deprecated...</td>\n",
       "      <td>Improper Handling of Exceptional Conditions</td>\n",
       "      <td>The software does not handle or incorrectly ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CWE-79</td>\n",
       "      <td>CVE-2018-20594</td>\n",
       "      <td>https://github.com/hs-web/hsweb-framework/comm...</td>\n",
       "      <td>FlowableModelManagerController.java</td>\n",
       "      <td>b72a2275ed21240296c6539bae1049c56abb542f</td>\n",
       "      <td>java</td>\n",
       "      <td>@PathVariable(\"type\") @...</td>\n",
       "      <td>import lombok.SneakyThrows;\\nimport org.hswebf...</td>\n",
       "      <td>fix #107 修复反射型xss</td>\n",
       "      <td>Improper Neutralization of Input During Web Pa...</td>\n",
       "      <td>The software does not neutralize or incorrectl...</td>\n",
       "      <td>Cross-site scripting (XSS) vulnerabilities occ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CWE-863</td>\n",
       "      <td>CVE-2020-19005</td>\n",
       "      <td>https://github.com/94fzb/zrlog/commit/b2b4415e...</td>\n",
       "      <td>UploadService.java</td>\n",
       "      <td>b2b4415e2e59b6f18b0a62b633e71c96d63c43ba</td>\n",
       "      <td>java</td>\n",
       "      <td>, new HttpJsonArrayHandle&lt;...</td>\n",
       "      <td>import com.zrlog.web.util.PluginHelper;\\n     ...</td>\n",
       "      <td>Fix #48 forget remove token from ThreadLocal</td>\n",
       "      <td>Incorrect Authorization</td>\n",
       "      <td>The software performs an authorization check w...</td>\n",
       "      <td>Assuming a user with a given identity, authori...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CWE-79</td>\n",
       "      <td>CVE-2020-4070</td>\n",
       "      <td>https://github.com/w3c/css-validator/commit/e5...</td>\n",
       "      <td>StyleSheetParser.java</td>\n",
       "      <td>e5c09a9119167d3064db786d5f00d730b584a53b</td>\n",
       "      <td>java</td>\n",
       "      <td>-1, e));\\n</td>\n",
       "      <td>-1, new Exception(Messages...</td>\n",
       "      <td>escape also the throwable message, see #278</td>\n",
       "      <td>Improper Neutralization of Input During Web Pa...</td>\n",
       "      <td>The software does not neutralize or incorrectl...</td>\n",
       "      <td>Cross-site scripting (XSS) vulnerabilities occ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>CWE-79</td>\n",
       "      <td>CVE-2018-20594</td>\n",
       "      <td>https://github.com/hs-web/hsweb-framework/comm...</td>\n",
       "      <td>ModelType.java</td>\n",
       "      <td>b72a2275ed21240296c6539bae1049c56abb542f</td>\n",
       "      <td>java</td>\n",
       "      <td>NaN</td>\n",
       "      <td>package org.hswebframework.web.workflow.enums;...</td>\n",
       "      <td>fix #107 修复反射型xss</td>\n",
       "      <td>Improper Neutralization of Input During Web Pa...</td>\n",
       "      <td>The software does not neutralize or incorrectl...</td>\n",
       "      <td>Cross-site scripting (XSS) vulnerabilities occ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>CWE-79</td>\n",
       "      <td>CVE-2018-1000129</td>\n",
       "      <td>https://github.com/rhuss/jolokia/commit/5895d5...</td>\n",
       "      <td>MimeTypeUtil.java</td>\n",
       "      <td>5895d5c137c335e6b473e9dcb9baf748851bbc5f#diff-...</td>\n",
       "      <td>java</td>\n",
       "      <td>NaN</td>\n",
       "      <td>package org.jolokia.util;\\nimport java.util.re...</td>\n",
       "      <td>fix: Verify a given 'mimeType' and/or 'callbac...</td>\n",
       "      <td>Improper Neutralization of Input During Web Pa...</td>\n",
       "      <td>The software does not neutralize or incorrectl...</td>\n",
       "      <td>Cross-site scripting (XSS) vulnerabilities occ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>CWE-22</td>\n",
       "      <td>CVE-2020-7647</td>\n",
       "      <td>https://github.com/jooby-project/jooby/commit/...</td>\n",
       "      <td>AssetSource.java</td>\n",
       "      <td>34f526028e6cd0652125baa33936ffb6a8a4a009</td>\n",
       "      <td>java</td>\n",
       "      <td>NaN</td>\n",
       "      <td>package org.jooby.internal;\\nimport com.google...</td>\n",
       "      <td>asset: path traversal fix #1639</td>\n",
       "      <td>Improper Limitation of a Pathname to a Restric...</td>\n",
       "      <td>The software uses external input to construct ...</td>\n",
       "      <td>Many file operations are intended to take plac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>CWE-22</td>\n",
       "      <td>CVE-2020-7647</td>\n",
       "      <td>https://github.com/jooby-project/jooby/commit/...</td>\n",
       "      <td>Issue1639.java</td>\n",
       "      <td>34f526028e6cd0652125baa33936ffb6a8a4a009</td>\n",
       "      <td>java</td>\n",
       "      <td>NaN</td>\n",
       "      <td>package org.jooby.issues;\\nimport org.jooby.te...</td>\n",
       "      <td>asset: path traversal fix #1639</td>\n",
       "      <td>Improper Limitation of a Pathname to a Restric...</td>\n",
       "      <td>The software uses external input to construct ...</td>\n",
       "      <td>Many file operations are intended to take plac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>CWE-20</td>\n",
       "      <td>CVE-2019-10648</td>\n",
       "      <td>https://github.com/robo-code/robocode/commit/8...</td>\n",
       "      <td>DnsAttack.java</td>\n",
       "      <td>836c84635e982e74f2f2771b2c8640c3a34221bd#diff-...</td>\n",
       "      <td>java</td>\n",
       "      <td>NaN</td>\n",
       "      <td>package tested.robots;\\npublic class DnsAttack...</td>\n",
       "      <td>Bug-406: DNS interaction is not blocked by Rob...</td>\n",
       "      <td>Improper Input Validation</td>\n",
       "      <td>The product receives input or data, but it doe...</td>\n",
       "      <td>Input validation is a frequently-used techniqu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CWE-ID            CVE-ID  \\\n",
       "0    CWE-119     CVE-2014-3488   \n",
       "1    CWE-755     CVE-2018-8039   \n",
       "2     CWE-79    CVE-2018-20594   \n",
       "3    CWE-863    CVE-2020-19005   \n",
       "4     CWE-79     CVE-2020-4070   \n",
       "..       ...               ...   \n",
       "353   CWE-79    CVE-2018-20594   \n",
       "354   CWE-79  CVE-2018-1000129   \n",
       "355   CWE-22     CVE-2020-7647   \n",
       "356   CWE-22     CVE-2020-7647   \n",
       "357   CWE-20    CVE-2019-10648   \n",
       "\n",
       "                                              Git Link  \\\n",
       "0    https://github.com/netty/netty/commit/2fa9400a...   \n",
       "1    https://github.com/apache/cxf/commit/fae6fabf9...   \n",
       "2    https://github.com/hs-web/hsweb-framework/comm...   \n",
       "3    https://github.com/94fzb/zrlog/commit/b2b4415e...   \n",
       "4    https://github.com/w3c/css-validator/commit/e5...   \n",
       "..                                                 ...   \n",
       "353  https://github.com/hs-web/hsweb-framework/comm...   \n",
       "354  https://github.com/rhuss/jolokia/commit/5895d5...   \n",
       "355  https://github.com/jooby-project/jooby/commit/...   \n",
       "356  https://github.com/jooby-project/jooby/commit/...   \n",
       "357  https://github.com/robo-code/robocode/commit/8...   \n",
       "\n",
       "                               File Name  \\\n",
       "0                        SslHandler.java   \n",
       "1         HttpsURLConnectionFactory.java   \n",
       "2    FlowableModelManagerController.java   \n",
       "3                     UploadService.java   \n",
       "4                  StyleSheetParser.java   \n",
       "..                                   ...   \n",
       "353                       ModelType.java   \n",
       "354                    MimeTypeUtil.java   \n",
       "355                     AssetSource.java   \n",
       "356                       Issue1639.java   \n",
       "357                       DnsAttack.java   \n",
       "\n",
       "                                                commit Language  \\\n",
       "0             2fa9400a59d0563a66908aba55c41e7285a04994     java   \n",
       "1             fae6fabf9bd7647f5e9cb68897a7d72b545b741b     java   \n",
       "2             b72a2275ed21240296c6539bae1049c56abb542f     java   \n",
       "3             b2b4415e2e59b6f18b0a62b633e71c96d63c43ba     java   \n",
       "4             e5c09a9119167d3064db786d5f00d730b584a53b     java   \n",
       "..                                                 ...      ...   \n",
       "353           b72a2275ed21240296c6539bae1049c56abb542f     java   \n",
       "354  5895d5c137c335e6b473e9dcb9baf748851bbc5f#diff-...     java   \n",
       "355           34f526028e6cd0652125baa33936ffb6a8a4a009     java   \n",
       "356           34f526028e6cd0652125baa33936ffb6a8a4a009     java   \n",
       "357  836c84635e982e74f2f2771b2c8640c3a34221bd#diff-...     java   \n",
       "\n",
       "                                                   Bad  \\\n",
       "0                                result = engine.un...   \n",
       "1                                       return true;\\n   \n",
       "2                           @PathVariable(\"type\") @...   \n",
       "3                        , new HttpJsonArrayHandle<...   \n",
       "4                                           -1, e));\\n   \n",
       "..                                                 ...   \n",
       "353                                                NaN   \n",
       "354                                                NaN   \n",
       "355                                                NaN   \n",
       "356                                                NaN   \n",
       "357                                                NaN   \n",
       "\n",
       "                                                  Good  \\\n",
       "0                            final int outAppBufSiz...   \n",
       "1                                      return false;\\n   \n",
       "2    import lombok.SneakyThrows;\\nimport org.hswebf...   \n",
       "3    import com.zrlog.web.util.PluginHelper;\\n     ...   \n",
       "4                        -1, new Exception(Messages...   \n",
       "..                                                 ...   \n",
       "353  package org.hswebframework.web.workflow.enums;...   \n",
       "354  package org.jolokia.util;\\nimport java.util.re...   \n",
       "355  package org.jooby.internal;\\nimport com.google...   \n",
       "356  package org.jooby.issues;\\nimport org.jooby.te...   \n",
       "357  package tested.robots;\\npublic class DnsAttack...   \n",
       "\n",
       "                                        Commit Message  \\\n",
       "0    Fix a bug where SslHandler does not handle SSL...   \n",
       "1    Fix hostname verification using the deprecated...   \n",
       "2                                    fix #107 修复反射型xss   \n",
       "3         Fix #48 forget remove token from ThreadLocal   \n",
       "4          escape also the throwable message, see #278   \n",
       "..                                                 ...   \n",
       "353                                  fix #107 修复反射型xss   \n",
       "354  fix: Verify a given 'mimeType' and/or 'callbac...   \n",
       "355                    asset: path traversal fix #1639   \n",
       "356                    asset: path traversal fix #1639   \n",
       "357  Bug-406: DNS interaction is not blocked by Rob...   \n",
       "\n",
       "                                              CWE Name  \\\n",
       "0    Improper Restriction of Operations within the ...   \n",
       "1          Improper Handling of Exceptional Conditions   \n",
       "2    Improper Neutralization of Input During Web Pa...   \n",
       "3                              Incorrect Authorization   \n",
       "4    Improper Neutralization of Input During Web Pa...   \n",
       "..                                                 ...   \n",
       "353  Improper Neutralization of Input During Web Pa...   \n",
       "354  Improper Neutralization of Input During Web Pa...   \n",
       "355  Improper Limitation of a Pathname to a Restric...   \n",
       "356  Improper Limitation of a Pathname to a Restric...   \n",
       "357                          Improper Input Validation   \n",
       "\n",
       "                                       CWE Description  \\\n",
       "0    The software performs operations on a memory b...   \n",
       "1    The software does not handle or incorrectly ha...   \n",
       "2    The software does not neutralize or incorrectl...   \n",
       "3    The software performs an authorization check w...   \n",
       "4    The software does not neutralize or incorrectl...   \n",
       "..                                                 ...   \n",
       "353  The software does not neutralize or incorrectl...   \n",
       "354  The software does not neutralize or incorrectl...   \n",
       "355  The software uses external input to construct ...   \n",
       "356  The software uses external input to construct ...   \n",
       "357  The product receives input or data, but it doe...   \n",
       "\n",
       "                              CWE Extended Description  Unnamed: 12  \\\n",
       "0    Certain languages allow direct addressing of m...          NaN   \n",
       "1                                                  NaN          NaN   \n",
       "2    Cross-site scripting (XSS) vulnerabilities occ...          NaN   \n",
       "3    Assuming a user with a given identity, authori...          NaN   \n",
       "4    Cross-site scripting (XSS) vulnerabilities occ...          NaN   \n",
       "..                                                 ...          ...   \n",
       "353  Cross-site scripting (XSS) vulnerabilities occ...          NaN   \n",
       "354  Cross-site scripting (XSS) vulnerabilities occ...          NaN   \n",
       "355  Many file operations are intended to take plac...          NaN   \n",
       "356  Many file operations are intended to take plac...          NaN   \n",
       "357  Input validation is a frequently-used techniqu...          NaN   \n",
       "\n",
       "     Unnamed: 13  Unnamed: 14  \n",
       "0          314.0        869.0  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "..           ...          ...  \n",
       "353          NaN          NaN  \n",
       "354          NaN          NaN  \n",
       "355          NaN          NaN  \n",
       "356          NaN          NaN  \n",
       "357          NaN          NaN  \n",
       "\n",
       "[358 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3YdXP3VQDnU"
   },
   "outputs": [],
   "source": [
    "# embedding bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3679,
     "status": "ok",
     "timestamp": 1666667966050,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "iWSvn7-Wz3ha",
    "outputId": "3156639c-383d-40cd-d5fc-8bbc850815d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total records\n",
      "345\n",
      "max dimension\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "testFile = open(\"tensorTest.txt\",\"w\")\n",
    "vectors_table= []\n",
    "vectors_table_test= []\n",
    "vectors_table_padded= []\n",
    "countExecuted = 0\n",
    "size_list = []\n",
    "for i in range(len(df)):\n",
    "    '''\n",
    "    if i == 5:\n",
    "        break\n",
    "    '''\n",
    "    #bad code\n",
    "    temp = str(df.iloc[i].tolist()[6])\n",
    "    temp2 = temp.replace(\"\\n\", \" \")\n",
    "    temp2 = temp.replace(\"\\\"\", \" \")\n",
    "\n",
    "    #CWE name + description\n",
    "    temp3 = str(df.iloc[i].tolist()[9])+str(df.iloc[i].tolist()[10])\n",
    "\n",
    "    totLenght = len(temp2) + len(temp3)\n",
    "    '''\n",
    "    if totLenght > 512:\n",
    "        \n",
    "        print(\"len\")\n",
    "        print(totLenght)\n",
    "        print(\"quotient\")\n",
    "        quotient = totLenght/512\n",
    "        print(quotient)\n",
    "        print(\"remainder\")\n",
    "        remainder = totLenght%512\n",
    "        print(remainder)\n",
    "        \n",
    "        continue\n",
    "    else:\n",
    "        countExecuted += 1\n",
    "    '''\n",
    "\n",
    "    nl_tokens=tokenizer.tokenize(temp3)\n",
    "    code_tokens=tokenizer.tokenize(temp2)\n",
    "    if len(nl_tokens)+len(code_tokens) > 512:\n",
    "        '''\n",
    "        print(\"len\")\n",
    "        print(totLenght)\n",
    "        print(\"quotient\")\n",
    "        quotient = totLenght/512\n",
    "        print(quotient)\n",
    "        print(\"remainder\")\n",
    "        remainder = totLenght%512\n",
    "        print(remainder)\n",
    "        '''\n",
    "        continue\n",
    "    else:\n",
    "        countExecuted += 1\n",
    "    \n",
    "    #bimodal\n",
    "    #tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "    \n",
    "    #unimodal\n",
    "    tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "    \n",
    "    \n",
    "    tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "    #print(tokens)\n",
    "    #print(\"len token\")\n",
    "    #print(len(tokens))\n",
    "    \n",
    "    torch. set_printoptions(profile=\"full\")\n",
    "    context_embeddings=model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "\n",
    "    \n",
    "    #testFile.write(\"\\n####\\n\")\n",
    "    #testFile.write(str(context_embeddings))\n",
    "    \n",
    "    \n",
    "    #vectors_table.append(context_embeddings)\n",
    "    vectors_table_test.append(context_embeddings[-1,::])\n",
    "    lenV = len(vectors_table_test)\n",
    "    c = list(vectors_table_test[lenV-1].size())\n",
    "    #print(\"current d\")\n",
    "    #print(c[0],c[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    t =list(context_embeddings.size())\n",
    "    \n",
    "    size_list.append(t[1])\n",
    "    \n",
    "    target = torch.zeros(496, 768)\n",
    "    source = context_embeddings[-1,::]\n",
    "    target[  :c[0]] = source\n",
    "    vectors_table_padded.append(target)\n",
    "    \n",
    "testFile.close()  \n",
    "\n",
    "print(\"total records\")\n",
    "print(countExecuted)\n",
    "print(\"max dimension\")\n",
    "print(max(size_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors_table_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=Tensor, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17512/1471457946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors_table_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors_table_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/samiha/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3436\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3437\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=Tensor, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(vectors_table_test[0],vectors_table_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    }
   ],
   "source": [
    "print(len(vectors_table_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([254, 768])\n",
      "torch.Size([53, 768])\n",
      "torch.Size([254, 768])\n"
     ]
    }
   ],
   "source": [
    "    target = torch.zeros(254, 768)\n",
    "    print(target.shape)\n",
    "    source = context_embeddings[-1,::]\n",
    "    print(source.shape)\n",
    "    target[  :53] = source\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1666667968539,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "iBSVyNQSJO1X",
    "outputId": "b945ebd0-0c75-4dbe-bf55-99ea5bf4c4b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57, 768])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_table_test[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 44899,
     "status": "error",
     "timestamp": 1666666936733,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "ICejl39KExy-",
    "outputId": "18b7c154-7d8a-42c3-ffcc-b66bd49b48bd"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e6daf2b083a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m!=\u001b[0m \u001b[0;34m'!!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0minsert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mvectors_table_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('tensorTest2.txt','r') as f:\n",
    "  insert = \"\"\n",
    "  for line in f:\n",
    "    while(line!= '!!!!'):\n",
    "      insert = insert + line\n",
    "  vectors_table_test.append(insert)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1666665264145,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "po6q7Sml9dTg"
   },
   "outputs": [],
   "source": [
    "\n",
    "t = []\n",
    "t = vectors_table_test[0].replace('tensor([',' ').replace(']]],',' ]]').replace('grad_fn=<NativeLayerNormBackward0>)',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1666665372729,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "6GGzNIce-wpZ"
   },
   "outputs": [],
   "source": [
    "tr = []\n",
    "tr.append(vectors_table_test[0].replace('tensor([','').replace(']]],',' ]]').replace('grad_fn=<NativeLayerNormBackward0>)',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7TYhlL0C7fS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLuEwMLv-8hM"
   },
   "outputs": [],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1666665108362,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "Xj79GZKKQJwj"
   },
   "outputs": [],
   "source": [
    "# embedding good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1666627130025,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "Ky3i03krQJ9m",
    "outputId": "7865b144-111c-410f-b813-3e43e5647f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total records\n",
      "298\n",
      "max dimension\n",
      "496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "testFile = open(\"tensorTest.txt\",\"w\")\n",
    "#vectors_table= []\n",
    "vectors_table_test= []\n",
    "#vectors_table_padded= []\n",
    "countExecuted = 0\n",
    "size_list = []\n",
    "for i in range(len(df)):\n",
    "    '''\n",
    "    if i ==5:\n",
    "        break\n",
    "    '''\n",
    "    #good code\n",
    "    temp = str(df.iloc[i].tolist()[7])\n",
    "    temp2 = temp.replace(\"\\n\", \" \")\n",
    "    temp2 = temp.replace(\"\\\"\", \" \")\n",
    "\n",
    "    #commit message\n",
    "    temp3 = str(df.iloc[i].tolist()[8])\n",
    "\n",
    "    totLenght = len(temp2) + len(temp3)\n",
    "    '''\n",
    "    if totLenght > 512:\n",
    "        \n",
    "        print(\"len\")\n",
    "        print(totLenght)\n",
    "        print(\"quotient\")\n",
    "        quotient = totLenght/512\n",
    "        print(quotient)\n",
    "        print(\"remainder\")\n",
    "        remainder = totLenght%512\n",
    "        print(remainder)\n",
    "        \n",
    "        continue\n",
    "    else:\n",
    "        countExecuted += 1\n",
    "    '''\n",
    "\n",
    "    nl_tokens=tokenizer.tokenize(temp3)\n",
    "    code_tokens=tokenizer.tokenize(temp2)\n",
    "    if len(nl_tokens)+len(code_tokens) > 512:\n",
    "        '''\n",
    "        print(\"len\")\n",
    "        print(totLenght)\n",
    "        print(\"quotient\")\n",
    "        quotient = totLenght/512\n",
    "        print(quotient)\n",
    "        print(\"remainder\")\n",
    "        remainder = totLenght%512\n",
    "        print(remainder)\n",
    "        '''\n",
    "        continue\n",
    "    else:\n",
    "        countExecuted += 1\n",
    "    \n",
    "    #bimodal\n",
    "    #tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "    \n",
    "    #unimodal\n",
    "    tokens=[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "    \n",
    "    \n",
    "    tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "    #print(tokens)\n",
    "    #print(\"len token\")\n",
    "    #print(len(tokens))\n",
    "    \n",
    "    torch. set_printoptions(profile=\"full\")\n",
    "    context_embeddings=model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "\n",
    "    \n",
    "    #testFile.write(\"\\n####\\n\")\n",
    "    #testFile.write(str(context_embeddings))\n",
    "    \n",
    "    \n",
    "    #vectors_table.append(context_embeddings)\n",
    "    vectors_table_test.append(context_embeddings[-1,::])\n",
    "    lenV = len(vectors_table_test)\n",
    "    c = list(vectors_table_test[lenV-1].size())\n",
    "    #print(\"current d\")\n",
    "    #print(c[0],c[1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    t =list(context_embeddings.size())\n",
    "    \n",
    "    size_list.append(t[1])\n",
    "    \n",
    "    target = torch.zeros(496, 768)\n",
    "    source = context_embeddings[-1,::]\n",
    "    target[  :c[0]] = source\n",
    "    vectors_table_padded.append(target)\n",
    "    \n",
    "testFile.close()  \n",
    "\n",
    "print(\"total records\")\n",
    "print(countExecuted)\n",
    "print(\"max dimension\")\n",
    "print(max(size_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors_table_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1666650037720,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "xmaX5f2EFVq7",
    "outputId": "232e2f07-ad04-400d-eda6-163da5f4503c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 57, 768])\n",
      "1 torch.Size([1, 104, 768])\n",
      "2 torch.Size([1, 115, 768])\n",
      "3 torch.Size([1, 195, 768])\n",
      "4 torch.Size([1, 60, 768])\n",
      "5 torch.Size([1, 239, 768])\n",
      "6 torch.Size([1, 83, 768])\n",
      "7 torch.Size([1, 79, 768])\n",
      "8 torch.Size([1, 32, 768])\n",
      "9 torch.Size([1, 54, 768])\n",
      "10 torch.Size([1, 54, 768])\n",
      "11 torch.Size([1, 54, 768])\n",
      "12 torch.Size([1, 84, 768])\n",
      "13 torch.Size([1, 84, 768])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vectors_table)):\n",
    "  print(i,vectors_table[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1666650040377,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "ktg6MyTgFQ2R",
    "outputId": "2c352d54-1fc7-4401-90da-f690548eaf09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 57, 768])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_table[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1666650075031,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "swJJDw5vFahb"
   },
   "outputs": [],
   "source": [
    "t2 = []\n",
    "t2.append(vectors_table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1666649086544,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "rY34-gpMFFJp",
    "outputId": "a0baffa6-7037-46e2-9222-52eb88b6d729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# compute cosine similarity\n",
    "cosi = torch.nn.CosineSimilarity(dim=1)\n",
    "output = cosi(vectors_table[0], vectors_table[0])\n",
    "\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXfsFxYbwDZ4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kw_G5Ix128Cx"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5yfx99n_7u1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[1., 1.], [1., 1.]]\n",
    "y_pred = [[1., 1.], [-1., -1.]]\n",
    "vectors_table[1] = vectors_table[1].detach().numpy()\n",
    "vectors_table[2] = vectors_table[2].detach().numpy()\n",
    "consine_sim_tensor = tf.keras.losses.cosine_similarity(vectors_table[1], vectors_table[2], axis=1)\n",
    "print(consine_sim_tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25mgC7f5yDjZ"
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "results = list()\n",
    "\n",
    "for i in range(0,len(vectors_table)):\n",
    "  result = 1 - spatial.distance.cosine(test[0], test[0])\n",
    "  results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: scipy in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /home/varshaponnaganti/.conda/envs/samiha/lib/python3.7/site-packages (from scipy) (1.21.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1666668071887,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "KhiRwyw4Hbop",
    "outputId": "65c2b6e5-170f-4203-cd8c-8841e2be8804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6359401643276215\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "#A = np.array([[1,23,2,5,6,2,2,6,2],[12,4,5,5],[1,2,4],[1],[2],[2]], dtype=object )\n",
    "#B = np.array([[1,23,2,5,6,2,2,6,2],[12,4,5,5],[1,2,4],[1],[2],[2]], dtype=object )\n",
    "\n",
    "#t2[0] = t2[0].detach().numpy()\n",
    "#vectors_table_padded[1] = vectors_table_padded[1].detach().numpy()\n",
    "#vectors_table_padded[0] = vectors_table_padded[0].detach().numpy()\n",
    "#Aflat = np.hstack(A)\n",
    "#Bflat = np.hstack(B)\n",
    "\n",
    "Aflat = np.hstack(vectors_table_padded[0])\n",
    "Bflat = np.hstack(vectors_table_padded[1])\n",
    "\n",
    "#Aflat = np.array(test[0])\n",
    "#Bflat = np.array(test[0])\n",
    "\n",
    "\n",
    "dist = distance.cosine(Aflat, Bflat)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open('similarity.txt','w')\n",
    "f.write(\"\\n\")\n",
    "\n",
    "for i in range(0,len(vectors_table_padded)):\n",
    "    vectors_table_padded[i] = vectors_table_padded[i].detach().numpy()\n",
    "\n",
    "for i in range(0,len(vectors_table_padded)):\n",
    "  temp = list()\n",
    "  for j in range(0,len(vectors_table_padded)):\n",
    "    \n",
    "    Aflat = np.hstack(vectors_table_padded[i])\n",
    "    Bflat = np.hstack(vectors_table_padded[j])\n",
    "    dist = distance.cosine(Aflat, Bflat)\n",
    "    resultOne = 1 - dist\n",
    "    temp.append(resultOne)\n",
    "    \n",
    "    \n",
    "    f.write(str(resultOne)+\" \")\n",
    " \n",
    "  f.write(\"\\n\")\n",
    "f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 644)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "  \n",
    "# read text file into pandas DataFrame\n",
    "dfSim = pd.read_csv(\"similarity.txt\",delimiter=\" \", header = None)\n",
    "  \n",
    "# display DataFrame\n",
    "print(dfSim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>640</th>\n",
       "      <th>641</th>\n",
       "      <th>642</th>\n",
       "      <th>643</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.356913</td>\n",
       "      <td>0.399006</td>\n",
       "      <td>0.298287</td>\n",
       "      <td>0.712428</td>\n",
       "      <td>0.305055</td>\n",
       "      <td>0.719981</td>\n",
       "      <td>0.428845</td>\n",
       "      <td>0.731045</td>\n",
       "      <td>0.439701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558609</td>\n",
       "      <td>0.575438</td>\n",
       "      <td>0.668021</td>\n",
       "      <td>0.528661</td>\n",
       "      <td>0.473276</td>\n",
       "      <td>0.388450</td>\n",
       "      <td>0.529966</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.630308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715582</td>\n",
       "      <td>0.800581</td>\n",
       "      <td>0.383706</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.314308</td>\n",
       "      <td>0.638180</td>\n",
       "      <td>0.293543</td>\n",
       "      <td>0.586558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222830</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.257765</td>\n",
       "      <td>0.204643</td>\n",
       "      <td>0.477221</td>\n",
       "      <td>0.591220</td>\n",
       "      <td>0.202292</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.360323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399006</td>\n",
       "      <td>0.715582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.676032</td>\n",
       "      <td>0.336952</td>\n",
       "      <td>0.735491</td>\n",
       "      <td>0.358009</td>\n",
       "      <td>0.694008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262896</td>\n",
       "      <td>0.265213</td>\n",
       "      <td>0.317141</td>\n",
       "      <td>0.253427</td>\n",
       "      <td>0.591205</td>\n",
       "      <td>0.726699</td>\n",
       "      <td>0.251220</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0.441195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298287</td>\n",
       "      <td>0.800581</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>0.916925</td>\n",
       "      <td>0.265832</td>\n",
       "      <td>0.575406</td>\n",
       "      <td>0.251965</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202294</td>\n",
       "      <td>0.183986</td>\n",
       "      <td>0.228315</td>\n",
       "      <td>0.188814</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>0.542072</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>0.331729</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712428</td>\n",
       "      <td>0.383706</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364045</td>\n",
       "      <td>0.665702</td>\n",
       "      <td>0.495704</td>\n",
       "      <td>0.660651</td>\n",
       "      <td>0.495032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507293</td>\n",
       "      <td>0.510359</td>\n",
       "      <td>0.593747</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.532505</td>\n",
       "      <td>0.441775</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>0.610197</td>\n",
       "      <td>0.713824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.473276</td>\n",
       "      <td>0.477221</td>\n",
       "      <td>0.591205</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>0.532505</td>\n",
       "      <td>0.429550</td>\n",
       "      <td>0.415879</td>\n",
       "      <td>0.675099</td>\n",
       "      <td>0.438151</td>\n",
       "      <td>0.683748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358938</td>\n",
       "      <td>0.372118</td>\n",
       "      <td>0.429373</td>\n",
       "      <td>0.337146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>0.339302</td>\n",
       "      <td>0.431325</td>\n",
       "      <td>0.600198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.388450</td>\n",
       "      <td>0.591220</td>\n",
       "      <td>0.726699</td>\n",
       "      <td>0.542072</td>\n",
       "      <td>0.441775</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>0.337824</td>\n",
       "      <td>0.739984</td>\n",
       "      <td>0.347939</td>\n",
       "      <td>0.685557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>0.291724</td>\n",
       "      <td>0.346322</td>\n",
       "      <td>0.274200</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274644</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.484939</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0.529966</td>\n",
       "      <td>0.202292</td>\n",
       "      <td>0.251220</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>0.186105</td>\n",
       "      <td>0.560003</td>\n",
       "      <td>0.283140</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702551</td>\n",
       "      <td>0.671159</td>\n",
       "      <td>0.620220</td>\n",
       "      <td>0.769575</td>\n",
       "      <td>0.339302</td>\n",
       "      <td>0.274644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614804</td>\n",
       "      <td>0.441905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>0.610197</td>\n",
       "      <td>0.237402</td>\n",
       "      <td>0.709798</td>\n",
       "      <td>0.363440</td>\n",
       "      <td>0.695937</td>\n",
       "      <td>0.367523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640431</td>\n",
       "      <td>0.657099</td>\n",
       "      <td>0.764466</td>\n",
       "      <td>0.609510</td>\n",
       "      <td>0.431325</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.614804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576362</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0.630308</td>\n",
       "      <td>0.360323</td>\n",
       "      <td>0.441195</td>\n",
       "      <td>0.331729</td>\n",
       "      <td>0.713824</td>\n",
       "      <td>0.330404</td>\n",
       "      <td>0.550802</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>0.575259</td>\n",
       "      <td>0.503587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473478</td>\n",
       "      <td>0.473057</td>\n",
       "      <td>0.564383</td>\n",
       "      <td>0.445162</td>\n",
       "      <td>0.600198</td>\n",
       "      <td>0.484939</td>\n",
       "      <td>0.441905</td>\n",
       "      <td>0.576362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.356913  0.399006  0.298287  0.712428  0.305055  0.719981   \n",
       "1    0.356913  1.000000  0.715582  0.800581  0.383706  0.810455  0.314308   \n",
       "2    0.399006  0.715582  1.000000  0.675399  0.446146  0.676032  0.336952   \n",
       "3    0.298287  0.800581  0.675399  1.000000  0.357959  0.916925  0.265832   \n",
       "4    0.712428  0.383706  0.446146  0.357959  1.000000  0.364045  0.665702   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "638  0.473276  0.477221  0.591205  0.425054  0.532505  0.429550  0.415879   \n",
       "639  0.388450  0.591220  0.726699  0.542072  0.441775  0.540086  0.337824   \n",
       "640  0.529966  0.202292  0.251220  0.182509  0.471799  0.186105  0.560003   \n",
       "641  0.676904  0.258735  0.315433  0.237040  0.610197  0.237402  0.709798   \n",
       "642  0.630308  0.360323  0.441195  0.331729  0.713824  0.330404  0.550802   \n",
       "\n",
       "          7         8         9    ...       634       635       636  \\\n",
       "0    0.428845  0.731045  0.439701  ...  0.558609  0.575438  0.668021   \n",
       "1    0.638180  0.293543  0.586558  ...  0.222830  0.216848  0.257765   \n",
       "2    0.735491  0.358009  0.694008  ...  0.262896  0.265213  0.317141   \n",
       "3    0.575406  0.251965  0.541600  ...  0.202294  0.183986  0.228315   \n",
       "4    0.495704  0.660651  0.495032  ...  0.507293  0.510359  0.593747   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "638  0.675099  0.438151  0.683748  ...  0.358938  0.372118  0.429373   \n",
       "639  0.739984  0.347939  0.685557  ...  0.296866  0.291724  0.346322   \n",
       "640  0.283140  0.533433  0.284657  ...  0.702551  0.671159  0.620220   \n",
       "641  0.363440  0.695937  0.367523  ...  0.640431  0.657099  0.764466   \n",
       "642  0.511334  0.575259  0.503587  ...  0.473478  0.473057  0.564383   \n",
       "\n",
       "          637       638       639       640       641       642  643  \n",
       "0    0.528661  0.473276  0.388450  0.529966  0.676904  0.630308  NaN  \n",
       "1    0.204643  0.477221  0.591220  0.202292  0.258735  0.360323  NaN  \n",
       "2    0.253427  0.591205  0.726699  0.251220  0.315433  0.441195  NaN  \n",
       "3    0.188814  0.425054  0.542072  0.182509  0.237040  0.331729  NaN  \n",
       "4    0.473986  0.532505  0.441775  0.471799  0.610197  0.713824  NaN  \n",
       "..        ...       ...       ...       ...       ...       ...  ...  \n",
       "638  0.337146  1.000000  0.636875  0.339302  0.431325  0.600198  NaN  \n",
       "639  0.274200  0.636875  1.000000  0.274644  0.344413  0.484939  NaN  \n",
       "640  0.769575  0.339302  0.274644  1.000000  0.614804  0.441905  NaN  \n",
       "641  0.609510  0.431325  0.344413  0.614804  1.000000  0.576362  NaN  \n",
       "642  0.445162  0.600198  0.484939  0.441905  0.576362  1.000000  NaN  \n",
       "\n",
       "[643 rows x 644 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 643 is out of bounds for axis 0 with size 643",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17512/76016626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfSim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfSim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m643\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/samiha/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4614\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4616\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4618\u001b[0m             \u001b[0;31m# error: Argument 1 to \"ndim\" has incompatible type \"Union[ExtensionArray,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 643 is out of bounds for axis 0 with size 643"
     ]
    }
   ],
   "source": [
    "dfSim.drop(dfSim.columns[[643]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>640</th>\n",
       "      <th>641</th>\n",
       "      <th>642</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.356913</td>\n",
       "      <td>0.399006</td>\n",
       "      <td>0.298287</td>\n",
       "      <td>0.712428</td>\n",
       "      <td>0.305055</td>\n",
       "      <td>0.719981</td>\n",
       "      <td>0.428845</td>\n",
       "      <td>0.731045</td>\n",
       "      <td>0.439701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518820</td>\n",
       "      <td>0.558609</td>\n",
       "      <td>0.575438</td>\n",
       "      <td>0.668021</td>\n",
       "      <td>0.528661</td>\n",
       "      <td>0.473276</td>\n",
       "      <td>0.388450</td>\n",
       "      <td>0.529966</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.630308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715582</td>\n",
       "      <td>0.800581</td>\n",
       "      <td>0.383706</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.314308</td>\n",
       "      <td>0.638180</td>\n",
       "      <td>0.293543</td>\n",
       "      <td>0.586558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446548</td>\n",
       "      <td>0.222830</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.257765</td>\n",
       "      <td>0.204643</td>\n",
       "      <td>0.477221</td>\n",
       "      <td>0.591220</td>\n",
       "      <td>0.202292</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.360323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399006</td>\n",
       "      <td>0.715582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.676032</td>\n",
       "      <td>0.336952</td>\n",
       "      <td>0.735491</td>\n",
       "      <td>0.358009</td>\n",
       "      <td>0.694008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539966</td>\n",
       "      <td>0.262896</td>\n",
       "      <td>0.265213</td>\n",
       "      <td>0.317141</td>\n",
       "      <td>0.253427</td>\n",
       "      <td>0.591205</td>\n",
       "      <td>0.726699</td>\n",
       "      <td>0.251220</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0.441195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298287</td>\n",
       "      <td>0.800581</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>0.916925</td>\n",
       "      <td>0.265832</td>\n",
       "      <td>0.575406</td>\n",
       "      <td>0.251965</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403758</td>\n",
       "      <td>0.202294</td>\n",
       "      <td>0.183986</td>\n",
       "      <td>0.228315</td>\n",
       "      <td>0.188814</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>0.542072</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>0.331729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712428</td>\n",
       "      <td>0.383706</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364045</td>\n",
       "      <td>0.665702</td>\n",
       "      <td>0.495704</td>\n",
       "      <td>0.660651</td>\n",
       "      <td>0.495032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590588</td>\n",
       "      <td>0.507293</td>\n",
       "      <td>0.510359</td>\n",
       "      <td>0.593747</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.532505</td>\n",
       "      <td>0.441775</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>0.610197</td>\n",
       "      <td>0.713824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.473276</td>\n",
       "      <td>0.477221</td>\n",
       "      <td>0.591205</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>0.532505</td>\n",
       "      <td>0.429550</td>\n",
       "      <td>0.415879</td>\n",
       "      <td>0.675099</td>\n",
       "      <td>0.438151</td>\n",
       "      <td>0.683748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729708</td>\n",
       "      <td>0.358938</td>\n",
       "      <td>0.372118</td>\n",
       "      <td>0.429373</td>\n",
       "      <td>0.337146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>0.339302</td>\n",
       "      <td>0.431325</td>\n",
       "      <td>0.600198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.388450</td>\n",
       "      <td>0.591220</td>\n",
       "      <td>0.726699</td>\n",
       "      <td>0.542072</td>\n",
       "      <td>0.441775</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>0.337824</td>\n",
       "      <td>0.739984</td>\n",
       "      <td>0.347939</td>\n",
       "      <td>0.685557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.296866</td>\n",
       "      <td>0.291724</td>\n",
       "      <td>0.346322</td>\n",
       "      <td>0.274200</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274644</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.484939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0.529966</td>\n",
       "      <td>0.202292</td>\n",
       "      <td>0.251220</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>0.186105</td>\n",
       "      <td>0.560003</td>\n",
       "      <td>0.283140</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366499</td>\n",
       "      <td>0.702551</td>\n",
       "      <td>0.671159</td>\n",
       "      <td>0.620220</td>\n",
       "      <td>0.769575</td>\n",
       "      <td>0.339302</td>\n",
       "      <td>0.274644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614804</td>\n",
       "      <td>0.441905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>0.610197</td>\n",
       "      <td>0.237402</td>\n",
       "      <td>0.709798</td>\n",
       "      <td>0.363440</td>\n",
       "      <td>0.695937</td>\n",
       "      <td>0.367523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467832</td>\n",
       "      <td>0.640431</td>\n",
       "      <td>0.657099</td>\n",
       "      <td>0.764466</td>\n",
       "      <td>0.609510</td>\n",
       "      <td>0.431325</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.614804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0.630308</td>\n",
       "      <td>0.360323</td>\n",
       "      <td>0.441195</td>\n",
       "      <td>0.331729</td>\n",
       "      <td>0.713824</td>\n",
       "      <td>0.330404</td>\n",
       "      <td>0.550802</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>0.575259</td>\n",
       "      <td>0.503587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645572</td>\n",
       "      <td>0.473478</td>\n",
       "      <td>0.473057</td>\n",
       "      <td>0.564383</td>\n",
       "      <td>0.445162</td>\n",
       "      <td>0.600198</td>\n",
       "      <td>0.484939</td>\n",
       "      <td>0.441905</td>\n",
       "      <td>0.576362</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    1.000000  0.356913  0.399006  0.298287  0.712428  0.305055  0.719981   \n",
       "1    0.356913  1.000000  0.715582  0.800581  0.383706  0.810455  0.314308   \n",
       "2    0.399006  0.715582  1.000000  0.675399  0.446146  0.676032  0.336952   \n",
       "3    0.298287  0.800581  0.675399  1.000000  0.357959  0.916925  0.265832   \n",
       "4    0.712428  0.383706  0.446146  0.357959  1.000000  0.364045  0.665702   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "638  0.473276  0.477221  0.591205  0.425054  0.532505  0.429550  0.415879   \n",
       "639  0.388450  0.591220  0.726699  0.542072  0.441775  0.540086  0.337824   \n",
       "640  0.529966  0.202292  0.251220  0.182509  0.471799  0.186105  0.560003   \n",
       "641  0.676904  0.258735  0.315433  0.237040  0.610197  0.237402  0.709798   \n",
       "642  0.630308  0.360323  0.441195  0.331729  0.713824  0.330404  0.550802   \n",
       "\n",
       "          7         8         9    ...       633       634       635  \\\n",
       "0    0.428845  0.731045  0.439701  ...  0.518820  0.558609  0.575438   \n",
       "1    0.638180  0.293543  0.586558  ...  0.446548  0.222830  0.216848   \n",
       "2    0.735491  0.358009  0.694008  ...  0.539966  0.262896  0.265213   \n",
       "3    0.575406  0.251965  0.541600  ...  0.403758  0.202294  0.183986   \n",
       "4    0.495704  0.660651  0.495032  ...  0.590588  0.507293  0.510359   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "638  0.675099  0.438151  0.683748  ...  0.729708  0.358938  0.372118   \n",
       "639  0.739984  0.347939  0.685557  ...  0.618667  0.296866  0.291724   \n",
       "640  0.283140  0.533433  0.284657  ...  0.366499  0.702551  0.671159   \n",
       "641  0.363440  0.695937  0.367523  ...  0.467832  0.640431  0.657099   \n",
       "642  0.511334  0.575259  0.503587  ...  0.645572  0.473478  0.473057   \n",
       "\n",
       "          636       637       638       639       640       641       642  \n",
       "0    0.668021  0.528661  0.473276  0.388450  0.529966  0.676904  0.630308  \n",
       "1    0.257765  0.204643  0.477221  0.591220  0.202292  0.258735  0.360323  \n",
       "2    0.317141  0.253427  0.591205  0.726699  0.251220  0.315433  0.441195  \n",
       "3    0.228315  0.188814  0.425054  0.542072  0.182509  0.237040  0.331729  \n",
       "4    0.593747  0.473986  0.532505  0.441775  0.471799  0.610197  0.713824  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "638  0.429373  0.337146  1.000000  0.636875  0.339302  0.431325  0.600198  \n",
       "639  0.346322  0.274200  0.636875  1.000000  0.274644  0.344413  0.484939  \n",
       "640  0.620220  0.769575  0.339302  0.274644  1.000000  0.614804  0.441905  \n",
       "641  0.764466  0.609510  0.431325  0.344413  0.614804  1.000000  0.576362  \n",
       "642  0.564383  0.445162  0.600198  0.484939  0.441905  0.576362  1.000000  \n",
       "\n",
       "[643 rows x 643 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n"
     ]
    }
   ],
   "source": [
    "listBadGood = list()\n",
    "for i in range(0,345):\n",
    "  listBadGood.append(\"Bad\")\n",
    "\n",
    "for i in range(0,298):\n",
    "  listBadGood.append(\"Good\")\n",
    "print(len(listBadGood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "listIndex = list()\n",
    "for i in range(0,643):\n",
    "  listIndex.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSim['GroundTruth'] = listBadGood\n",
    "dfSim['Index'] = listIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "      <th>640</th>\n",
       "      <th>641</th>\n",
       "      <th>642</th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.356913</td>\n",
       "      <td>0.399006</td>\n",
       "      <td>0.298287</td>\n",
       "      <td>0.712428</td>\n",
       "      <td>0.305055</td>\n",
       "      <td>0.719981</td>\n",
       "      <td>0.428845</td>\n",
       "      <td>0.731045</td>\n",
       "      <td>0.439701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575438</td>\n",
       "      <td>0.668021</td>\n",
       "      <td>0.528661</td>\n",
       "      <td>0.473276</td>\n",
       "      <td>0.388450</td>\n",
       "      <td>0.529966</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.630308</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715582</td>\n",
       "      <td>0.800581</td>\n",
       "      <td>0.383706</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.314308</td>\n",
       "      <td>0.638180</td>\n",
       "      <td>0.293543</td>\n",
       "      <td>0.586558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.257765</td>\n",
       "      <td>0.204643</td>\n",
       "      <td>0.477221</td>\n",
       "      <td>0.591220</td>\n",
       "      <td>0.202292</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.360323</td>\n",
       "      <td>Bad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399006</td>\n",
       "      <td>0.715582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.676032</td>\n",
       "      <td>0.336952</td>\n",
       "      <td>0.735491</td>\n",
       "      <td>0.358009</td>\n",
       "      <td>0.694008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265213</td>\n",
       "      <td>0.317141</td>\n",
       "      <td>0.253427</td>\n",
       "      <td>0.591205</td>\n",
       "      <td>0.726699</td>\n",
       "      <td>0.251220</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0.441195</td>\n",
       "      <td>Bad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298287</td>\n",
       "      <td>0.800581</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>0.916925</td>\n",
       "      <td>0.265832</td>\n",
       "      <td>0.575406</td>\n",
       "      <td>0.251965</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183986</td>\n",
       "      <td>0.228315</td>\n",
       "      <td>0.188814</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>0.542072</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>0.331729</td>\n",
       "      <td>Bad</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.712428</td>\n",
       "      <td>0.383706</td>\n",
       "      <td>0.446146</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.364045</td>\n",
       "      <td>0.665702</td>\n",
       "      <td>0.495704</td>\n",
       "      <td>0.660651</td>\n",
       "      <td>0.495032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510359</td>\n",
       "      <td>0.593747</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.532505</td>\n",
       "      <td>0.441775</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>0.610197</td>\n",
       "      <td>0.713824</td>\n",
       "      <td>Bad</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.473276</td>\n",
       "      <td>0.477221</td>\n",
       "      <td>0.591205</td>\n",
       "      <td>0.425054</td>\n",
       "      <td>0.532505</td>\n",
       "      <td>0.429550</td>\n",
       "      <td>0.415879</td>\n",
       "      <td>0.675099</td>\n",
       "      <td>0.438151</td>\n",
       "      <td>0.683748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372118</td>\n",
       "      <td>0.429373</td>\n",
       "      <td>0.337146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>0.339302</td>\n",
       "      <td>0.431325</td>\n",
       "      <td>0.600198</td>\n",
       "      <td>Good</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.388450</td>\n",
       "      <td>0.591220</td>\n",
       "      <td>0.726699</td>\n",
       "      <td>0.542072</td>\n",
       "      <td>0.441775</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>0.337824</td>\n",
       "      <td>0.739984</td>\n",
       "      <td>0.347939</td>\n",
       "      <td>0.685557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291724</td>\n",
       "      <td>0.346322</td>\n",
       "      <td>0.274200</td>\n",
       "      <td>0.636875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274644</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.484939</td>\n",
       "      <td>Good</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0.529966</td>\n",
       "      <td>0.202292</td>\n",
       "      <td>0.251220</td>\n",
       "      <td>0.182509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>0.186105</td>\n",
       "      <td>0.560003</td>\n",
       "      <td>0.283140</td>\n",
       "      <td>0.533433</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671159</td>\n",
       "      <td>0.620220</td>\n",
       "      <td>0.769575</td>\n",
       "      <td>0.339302</td>\n",
       "      <td>0.274644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614804</td>\n",
       "      <td>0.441905</td>\n",
       "      <td>Good</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>0.610197</td>\n",
       "      <td>0.237402</td>\n",
       "      <td>0.709798</td>\n",
       "      <td>0.363440</td>\n",
       "      <td>0.695937</td>\n",
       "      <td>0.367523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657099</td>\n",
       "      <td>0.764466</td>\n",
       "      <td>0.609510</td>\n",
       "      <td>0.431325</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.614804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576362</td>\n",
       "      <td>Good</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0.630308</td>\n",
       "      <td>0.360323</td>\n",
       "      <td>0.441195</td>\n",
       "      <td>0.331729</td>\n",
       "      <td>0.713824</td>\n",
       "      <td>0.330404</td>\n",
       "      <td>0.550802</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>0.575259</td>\n",
       "      <td>0.503587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473057</td>\n",
       "      <td>0.564383</td>\n",
       "      <td>0.445162</td>\n",
       "      <td>0.600198</td>\n",
       "      <td>0.484939</td>\n",
       "      <td>0.441905</td>\n",
       "      <td>0.576362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Good</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 645 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    1.000000  0.356913  0.399006  0.298287  0.712428  0.305055  0.719981   \n",
       "1    0.356913  1.000000  0.715582  0.800581  0.383706  0.810455  0.314308   \n",
       "2    0.399006  0.715582  1.000000  0.675399  0.446146  0.676032  0.336952   \n",
       "3    0.298287  0.800581  0.675399  1.000000  0.357959  0.916925  0.265832   \n",
       "4    0.712428  0.383706  0.446146  0.357959  1.000000  0.364045  0.665702   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "638  0.473276  0.477221  0.591205  0.425054  0.532505  0.429550  0.415879   \n",
       "639  0.388450  0.591220  0.726699  0.542072  0.441775  0.540086  0.337824   \n",
       "640  0.529966  0.202292  0.251220  0.182509  0.471799  0.186105  0.560003   \n",
       "641  0.676904  0.258735  0.315433  0.237040  0.610197  0.237402  0.709798   \n",
       "642  0.630308  0.360323  0.441195  0.331729  0.713824  0.330404  0.550802   \n",
       "\n",
       "            7         8         9  ...       635       636       637  \\\n",
       "0    0.428845  0.731045  0.439701  ...  0.575438  0.668021  0.528661   \n",
       "1    0.638180  0.293543  0.586558  ...  0.216848  0.257765  0.204643   \n",
       "2    0.735491  0.358009  0.694008  ...  0.265213  0.317141  0.253427   \n",
       "3    0.575406  0.251965  0.541600  ...  0.183986  0.228315  0.188814   \n",
       "4    0.495704  0.660651  0.495032  ...  0.510359  0.593747  0.473986   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "638  0.675099  0.438151  0.683748  ...  0.372118  0.429373  0.337146   \n",
       "639  0.739984  0.347939  0.685557  ...  0.291724  0.346322  0.274200   \n",
       "640  0.283140  0.533433  0.284657  ...  0.671159  0.620220  0.769575   \n",
       "641  0.363440  0.695937  0.367523  ...  0.657099  0.764466  0.609510   \n",
       "642  0.511334  0.575259  0.503587  ...  0.473057  0.564383  0.445162   \n",
       "\n",
       "          638       639       640       641       642  GroundTruth  Index  \n",
       "0    0.473276  0.388450  0.529966  0.676904  0.630308          Bad      0  \n",
       "1    0.477221  0.591220  0.202292  0.258735  0.360323          Bad      1  \n",
       "2    0.591205  0.726699  0.251220  0.315433  0.441195          Bad      2  \n",
       "3    0.425054  0.542072  0.182509  0.237040  0.331729          Bad      3  \n",
       "4    0.532505  0.441775  0.471799  0.610197  0.713824          Bad      4  \n",
       "..        ...       ...       ...       ...       ...          ...    ...  \n",
       "638  1.000000  0.636875  0.339302  0.431325  0.600198         Good    638  \n",
       "639  0.636875  1.000000  0.274644  0.344413  0.484939         Good    639  \n",
       "640  0.339302  0.274644  1.000000  0.614804  0.441905         Good    640  \n",
       "641  0.431325  0.344413  0.614804  1.000000  0.576362         Good    641  \n",
       "642  0.600198  0.484939  0.441905  0.576362  1.000000         Good    642  \n",
       "\n",
       "[643 rows x 645 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"topResult.txt\",\"w\")\n",
    "ls = dfSim.values.tolist()\n",
    "lenOfData = 643\n",
    "\n",
    "for j in range(0,lenOfData):\n",
    "\n",
    "  temp = list()\n",
    "  for i in range(0,lenOfData):\n",
    "    temp.append(ls[j][i])\n",
    "  temp3= temp\n",
    "  res = sorted(range(len(temp)), key = lambda sub: temp[sub])[-6:]\n",
    "\n",
    "  if (j) in res:\n",
    "    res.remove(j)\n",
    "  else:\n",
    "    \n",
    "    res = sorted(range(len(temp)), key = lambda sub: temp[sub])[-5:]\n",
    "\n",
    "  temp2 = list()\n",
    "  f.write(str(ls[j][lenOfData])+\" \"+str(ls[j][lenOfData])+\" \")\n",
    "  temp3 = list()\n",
    "  for i in range(0,len(res)):\n",
    "    temp4 = list()\n",
    "\n",
    "    temp4.append(temp[res[i]])\n",
    "    temp4.append(res[i])\n",
    "    temp3.append(temp4)\n",
    "  new_data = sorted(temp3, key=lambda row: (row[0]), reverse=True)\n",
    "\n",
    "  res2=list()\n",
    "  for i in range(0,len(new_data)):\n",
    "\n",
    "    res2.append(new_data[i][1])\n",
    "\n",
    "  for i in range(0,len(res2)):\n",
    "\n",
    "    f.write(str(temp[res2[i]])+\" \"+str(res2[i])+\" \"+str(ls[res2[i]][lenOfData])+\" \")\n",
    "    temp2.append(ls[res2[i]][lenOfData])\n",
    "\n",
    "  f.write(\"\\n\")\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "  \n",
    "# read text file into pandas DataFrame\n",
    "df3 = pd.read_csv(\"topResult.txt\", sep=\" \", header=None)\n",
    "  \n",
    "# display DataFrame\n",
    "print(df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.796877</td>\n",
       "      <td>37</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.794213</td>\n",
       "      <td>535</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.794213</td>\n",
       "      <td>536</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.794213</td>\n",
       "      <td>537</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.792980</td>\n",
       "      <td>374</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.990557</td>\n",
       "      <td>345</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.812889</td>\n",
       "      <td>365</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.812459</td>\n",
       "      <td>22</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.805325</td>\n",
       "      <td>17</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.819815</td>\n",
       "      <td>12</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.819815</td>\n",
       "      <td>356</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.810874</td>\n",
       "      <td>10</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.808293</td>\n",
       "      <td>53</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.804849</td>\n",
       "      <td>11</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.916925</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.849880</td>\n",
       "      <td>26</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.840390</td>\n",
       "      <td>27</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.836345</td>\n",
       "      <td>381</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.836345</td>\n",
       "      <td>382</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.825077</td>\n",
       "      <td>358</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.804687</td>\n",
       "      <td>81</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.776223</td>\n",
       "      <td>521</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.775661</td>\n",
       "      <td>104</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.769913</td>\n",
       "      <td>448</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.784886</td>\n",
       "      <td>377</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.771445</td>\n",
       "      <td>107</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.770955</td>\n",
       "      <td>375</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.770495</td>\n",
       "      <td>428</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.766707</td>\n",
       "      <td>129</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.790214</td>\n",
       "      <td>478</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.787042</td>\n",
       "      <td>168</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.778188</td>\n",
       "      <td>504</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.773766</td>\n",
       "      <td>615</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.770673</td>\n",
       "      <td>15</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.793055</td>\n",
       "      <td>386</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.793055</td>\n",
       "      <td>387</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.769575</td>\n",
       "      <td>637</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.758194</td>\n",
       "      <td>368</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.755971</td>\n",
       "      <td>348</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.764466</td>\n",
       "      <td>636</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.753939</td>\n",
       "      <td>508</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>180</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.752601</td>\n",
       "      <td>19</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.745092</td>\n",
       "      <td>475</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.782712</td>\n",
       "      <td>110</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.768316</td>\n",
       "      <td>176</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.762930</td>\n",
       "      <td>200</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.758384</td>\n",
       "      <td>543</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.753211</td>\n",
       "      <td>161</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1         2    3     4         5    6     7         8    9   \\\n",
       "0     Bad   Bad  0.796877   37   Bad  0.794213  535  Good  0.794213  536   \n",
       "1     Bad   Bad  0.990557  345  Good  0.812889  365  Good  0.812459   22   \n",
       "2     Bad   Bad  0.819815   12   Bad  0.819815  356  Good  0.810874   10   \n",
       "3     Bad   Bad  0.916925    5   Bad  0.849880   26   Bad  0.840390   27   \n",
       "4     Bad   Bad  0.825077  358  Good  0.804687   81   Bad  0.776223  521   \n",
       "..    ...   ...       ...  ...   ...       ...  ...   ...       ...  ...   \n",
       "638  Good  Good  0.784886  377  Good  0.771445  107   Bad  0.770955  375   \n",
       "639  Good  Good  0.790214  478  Good  0.787042  168   Bad  0.778188  504   \n",
       "640  Good  Good  0.793055  386  Good  0.793055  387  Good  0.769575  637   \n",
       "641  Good  Good  0.764466  636  Good  0.753939  508  Good  0.752809  180   \n",
       "642  Good  Good  0.782712  110   Bad  0.768316  176   Bad  0.762930  200   \n",
       "\n",
       "       10        11   12    13        14   15    16  17  \n",
       "0    Good  0.794213  537  Good  0.792980  374  Good NaN  \n",
       "1     Bad  0.810455    5   Bad  0.805325   17   Bad NaN  \n",
       "2     Bad  0.808293   53   Bad  0.804849   11   Bad NaN  \n",
       "3     Bad  0.836345  381  Good  0.836345  382  Good NaN  \n",
       "4    Good  0.775661  104   Bad  0.769913  448  Good NaN  \n",
       "..    ...       ...  ...   ...       ...  ...   ...  ..  \n",
       "638  Good  0.770495  428  Good  0.766707  129   Bad NaN  \n",
       "639  Good  0.773766  615  Good  0.770673   15   Bad NaN  \n",
       "640  Good  0.758194  368  Good  0.755971  348  Good NaN  \n",
       "641   Bad  0.752601   19   Bad  0.745092  475  Good NaN  \n",
       "642   Bad  0.758384  543  Good  0.753211  161   Bad NaN  \n",
       "\n",
       "[643 rows x 18 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.drop(df3.columns[[17]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "listGood =list()\n",
    "listBad = list()\n",
    "\n",
    "for i in range(0,643):\n",
    "  bad =0\n",
    "  good =0\n",
    "  tList= df3.iloc[i].tolist()\n",
    "  #print(tList)\n",
    "  if tList[4] == 'Bad':\n",
    "    bad += 5*tList[2]\n",
    "  else:\n",
    "    good += 5*tList[2]\n",
    "\n",
    "  if tList[7] == 'Bad':\n",
    "    bad += 4*tList[5]\n",
    "  else:\n",
    "    good += 4*tList[5]\n",
    "\n",
    "  if tList[10] == 'Bad':\n",
    "    bad += 3*tList[8]\n",
    "  else:\n",
    "    good += 3*tList[8]\n",
    "  \n",
    "  if tList[13] == 'Bad':\n",
    "    bad += 2*tList[11]\n",
    "  else:\n",
    "    good += 2*tList[11]\n",
    "\n",
    "  if tList[16] == 'Bad':\n",
    "    bad += 1*tList[14]\n",
    "  else:\n",
    "    good += 1*tList[14]\n",
    "  \n",
    "  listGood.append(good)\n",
    "  listBad.append(bad)\n",
    "  #print(good)\n",
    "  #print(bad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n"
     ]
    }
   ],
   "source": [
    "print(len(listGood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[17]=listGood\n",
    "df3[18] = listBad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.803595</td>\n",
       "      <td>305</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.786575</td>\n",
       "      <td>76</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.785030</td>\n",
       "      <td>340</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.778699</td>\n",
       "      <td>60</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.770766</td>\n",
       "      <td>54</td>\n",
       "      <td>Bad</td>\n",
       "      <td>6.373065</td>\n",
       "      <td>5.474464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.833658</td>\n",
       "      <td>77</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.819028</td>\n",
       "      <td>92</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.800785</td>\n",
       "      <td>67</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.798925</td>\n",
       "      <td>142</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.789279</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.233882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.933327</td>\n",
       "      <td>29</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.933327</td>\n",
       "      <td>30</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.928378</td>\n",
       "      <td>24</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.872664</td>\n",
       "      <td>100</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.850124</td>\n",
       "      <td>65</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.780532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.931976</td>\n",
       "      <td>19</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.923036</td>\n",
       "      <td>71</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.916964</td>\n",
       "      <td>14</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.912601</td>\n",
       "      <td>118</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.895413</td>\n",
       "      <td>90</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.876774</td>\n",
       "      <td>20</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.841908</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.821442</td>\n",
       "      <td>98</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.804419</td>\n",
       "      <td>129</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.800916</td>\n",
       "      <td>58</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.625581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.997308</td>\n",
       "      <td>458</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.996048</td>\n",
       "      <td>457</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.838640</td>\n",
       "      <td>438</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.809137</td>\n",
       "      <td>414</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.762498</td>\n",
       "      <td>398</td>\n",
       "      <td>Good</td>\n",
       "      <td>13.867425</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.786588</td>\n",
       "      <td>301</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.768481</td>\n",
       "      <td>64</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.765036</td>\n",
       "      <td>135</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.762602</td>\n",
       "      <td>312</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>406</td>\n",
       "      <td>Good</td>\n",
       "      <td>6.217366</td>\n",
       "      <td>5.369032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.801194</td>\n",
       "      <td>355</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.783509</td>\n",
       "      <td>329</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.780027</td>\n",
       "      <td>366</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.779148</td>\n",
       "      <td>320</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.777130</td>\n",
       "      <td>377</td>\n",
       "      <td>Good</td>\n",
       "      <td>11.815515</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.791068</td>\n",
       "      <td>408</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.790037</td>\n",
       "      <td>92</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.788772</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad</td>\n",
       "      <td>0.786511</td>\n",
       "      <td>356</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.775363</td>\n",
       "      <td>304</td>\n",
       "      <td>Good</td>\n",
       "      <td>6.303724</td>\n",
       "      <td>5.526464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.761076</td>\n",
       "      <td>423</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.758678</td>\n",
       "      <td>346</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.747777</td>\n",
       "      <td>386</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.744008</td>\n",
       "      <td>293</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.743596</td>\n",
       "      <td>287</td>\n",
       "      <td>Good</td>\n",
       "      <td>11.315038</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1         2    3     4         5    6     7         8    9   \\\n",
       "0     Bad   Bad  0.803595  305  Good  0.786575   76   Bad  0.785030  340   \n",
       "1     Bad   Bad  0.833658   77   Bad  0.819028   92   Bad  0.800785   67   \n",
       "2     Bad   Bad  0.933327   29   Bad  0.933327   30   Bad  0.928378   24   \n",
       "3     Bad   Bad  0.931976   19   Bad  0.923036   71   Bad  0.916964   14   \n",
       "4     Bad   Bad  0.876774   20   Bad  0.841908    8   Bad  0.821442   98   \n",
       "..    ...   ...       ...  ...   ...       ...  ...   ...       ...  ...   \n",
       "459  Good  Good  0.997308  458  Good  0.996048  457  Good  0.838640  438   \n",
       "460  Good  Good  0.786588  301  Good  0.768481   64   Bad  0.765036  135   \n",
       "461  Good  Good  0.801194  355  Good  0.783509  329  Good  0.780027  366   \n",
       "462  Good  Good  0.791068  408  Good  0.790037   92   Bad  0.788772    3   \n",
       "463  Good  Good  0.761076  423  Good  0.758678  346  Good  0.747777  386   \n",
       "\n",
       "       10        11   12    13        14   15    16         17         18  \n",
       "0    Good  0.778699   60   Bad  0.770766   54   Bad   6.373065   5.474464  \n",
       "1     Bad  0.798925  142   Bad  0.789279    8   Bad   0.000000  12.233882  \n",
       "2     Bad  0.872664  100   Bad  0.850124   65   Bad   0.000000  13.780532  \n",
       "3     Bad  0.912601  118   Bad  0.895413   90   Bad   0.000000  13.823529  \n",
       "4     Bad  0.804419  129   Bad  0.800916   58   Bad   0.000000  12.625581  \n",
       "..    ...       ...  ...   ...       ...  ...   ...        ...        ...  \n",
       "459  Good  0.809137  414  Good  0.762498  398  Good  13.867425   0.000000  \n",
       "460   Bad  0.762602  312  Good  0.759223  406  Good   6.217366   5.369032  \n",
       "461  Good  0.779148  320  Good  0.777130  377  Good  11.815515   0.000000  \n",
       "462   Bad  0.786511  356  Good  0.775363  304  Good   6.303724   5.526464  \n",
       "463  Good  0.744008  293  Good  0.743596  287  Good  11.315038   0.000000  \n",
       "\n",
       "[464 rows x 19 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_excel(\"result.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1666647959195,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "coVP3tTT7imv"
   },
   "outputs": [],
   "source": [
    "target = torch.zeros(2, 3, 5)\n",
    "source = torch.ones(2, 3, 2)\n",
    "target[:, :, :2] = source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1666648126884,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "JMeBivBn97J4",
    "outputId": "5cbda724-87ba-44a0-e7b8-24992fb23034"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([57, 768])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].shape\n",
    "#test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1666648137511,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "Y1snpRWq-FWs",
    "outputId": "7a0c45d4-8444-45e0-b37f-f657b5737714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([119, 768])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1666648260554,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "PsGYbTBD-Ig1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15091/3273456854.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m119\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "target = torch.zeros(119,768)\n",
    "source = test[0]\n",
    "target[:57, :,] = source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1666648294431,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "BhTaR9yY9a2Y"
   },
   "outputs": [],
   "source": [
    "test.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1666648309049,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "JldveiPl-so-",
    "outputId": "f19e00cf-d54d-4a21-fc95-148bf950235e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1666647973592,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "2lwiZe8z9dFq",
    "outputId": "b740bcf2-fa63-42f8-e2ca-6e034e7b8c4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO-4L_ap7r7b"
   },
   "outputs": [],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1666647525691,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "iTGZcZO_7wBU",
    "outputId": "32c59ac9-4c4c-48a9-ff54-d2ebc4ff9aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000],\n",
       "        [0.6482, 0.3225, 0.7339, 0.0017, 0.8828, 0.8393, 0.9745, 0.3446, 0.3282,\n",
       "         0.8330, 0.0000],\n",
       "        [0.4897, 0.9547, 0.1091, 0.3188, 0.7557, 0.6667, 0.6882, 0.4242, 0.2827,\n",
       "         0.4811, 0.0000],\n",
       "        [0.0602, 0.2476, 0.6752, 0.8240, 0.1335, 0.8941, 0.2285, 0.1975, 0.4969,\n",
       "         0.5452, 0.0000],\n",
       "        [0.3492, 0.7617, 0.7538, 0.2998, 0.4752, 0.2386, 0.2879, 0.1575, 0.7816,\n",
       "         0.7653, 0.0000],\n",
       "        [0.9587, 0.9584, 0.6527, 0.5145, 0.8066, 0.3472, 0.6341, 0.6696, 0.9768,\n",
       "         0.1153, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1666332170891,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "1TqSEkruEZES",
    "outputId": "56dc0568-412b-4b6d-e72b-e270e4ac15a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1666645597278,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "tCGlkfiuIyiT",
    "outputId": "d3c17ea6-29e7-4b9b-af61-eac361f48d1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VO589dff9V1n"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = tf.constant(np.random.uniform(-1, 1, 10)) \n",
    "y = tf.constant(np.random.uniform(-1, 1, 10))\n",
    "s = tf.losses.cosine_distance(tf.nn.l2_normalize(x, 0), tf.nn.l2_normalize(y, 0), dim=0)\n",
    "print(tf.Session().run(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6294,
     "status": "ok",
     "timestamp": 1666647710881,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "XhbJo5zc1tKj",
    "outputId": "f3c5a75e-418b-4ba6-cef8-6901b29664d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 4.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.23.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 79.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.13.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=fe6af270292c5a71b8caac22a0e764f4e0efda9ae8cf8572d6476bdbccd9dd46\n",
      "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ThbdR_M4vwo"
   },
   "outputs": [],
   "source": [
    "vectors_table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3zO-jJy1d8H"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "print(\"type\")\n",
    "#print(type(vectors_table[0]))\n",
    "print(type(embeddings1))\n",
    "#print(embeddings1[1])\n",
    "#Compute cosine-similarities\n",
    "#cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "#cosine_scores = util.cos_sim(test[0],test2[0])\n",
    "cosine_scores = util.cos_sim(test[0],test[1])\n",
    "#Output the pairs with their score\n",
    "'''\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))\n",
    "'''\n",
    "print(\"S\")\n",
    "print(cosine_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLvwlB30-Hmv"
   },
   "outputs": [],
   "source": [
    "t = [3.5,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncgdrU7i-KT0"
   },
   "outputs": [],
   "source": [
    "t2 = [3,4.5,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9qn_vD57LJd"
   },
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBMbd1VZKUwz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1666332282838,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "HBenupw25Q_f",
    "outputId": "f39c69ff-026f-426b-f9e5-243b6336334e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1666645611830,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "3RNki_aO8axz"
   },
   "outputs": [],
   "source": [
    "test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1666626732711,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "D3BsFDJmsYtl",
    "outputId": "a1625df3-f2aa-45c2-db15-4eba3364580e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1666332699066,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "bSdWLlWo5X0G",
    "outputId": "b55168ae-66d0-4c17-d51b-ea4c5e70fdb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXh97mSU1hnu"
   },
   "outputs": [],
   "source": [
    "from python_utils import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1666645741110,
     "user": {
      "displayName": "Samiha Sharmin Shimmi",
      "userId": "10952472062329875127"
     },
     "user_tz": 300
    },
    "id": "bdS2OFx005W5",
    "outputId": "008eb268-1858-400c-d242-cc12c87544c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNe1CHguye2bRvGCwUt4xQP",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
